\documentclass[a4paper,11pt,twoside]{article}
%\documentclass[a4paper,11pt,twoside,se]{article}

\usepackage{UmUStudentReport}
\usepackage{verbatim}   % Multi-line comments using \begin{comment}
\usepackage{courier}    % Nicer fonts are used. (not necessary)
\usepackage{pslatex}    % Also nicer fonts. (not necessary)
\usepackage[pdftex]{graphicx}   % allows including pdf figures
\usepackage{listings}
%\usepackage{lmodern}   % Optional fonts. (not necessary)
%\usepackage{tabularx}
%\usepackage{microtype} % Provides some typographic improvements over default settings
%\usepackage{placeins}  % For aligning images with \FloatBarrier
%\usepackage{booktabs}  % For nice-looking tables
%\usepackage{titlesec}  % More granular control of sections.

% DOCUMENT INFO
% =============
\department{Institution för Datavetenskap}
\coursename{Datavetenskapens byggstenar 7.5 p}
\coursecode{DV160HT15}
\title{OU4 Data Representation}
\author{Lorenz Gerber ({\tt{dv15lgr@cs.umu.se}})} 
\date{2016-03-03}
%\revisiondate{2016-01-18}
\instructor{Lena Kallin Westin / Johan Eliasson / Emil Marklund / Lina
Ögren}


% DOCUMENT SETTINGS
% =================
\bibliographystyle{plain}
%\bibliographystyle{ieee}
\pagestyle{fancy}
\raggedbottom
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
%\graphicspath{{images/}}   %Path for images

\usepackage{float}
\floatstyle{ruled}
\newfloat{listing}{thp}{lop}
\floatname{listing}{Listing}


% DEFINES
% =======
%\newcommand{\mycommand}{<latex code>}

% DOCUMENT
% ========
\begin{document}
\lstset{language=C}
\maketitle

\tableofcontents
\newpage

\section{Introduction} 
In this assignment the aim was to specify three different possible
data representations for a spreadsheet application. The
representations were to be described such that they could be implemented
from the descriptions. Several criteria to judge the suitability of
the chosen representations were discussed in the mandatory seminar
\emph{OU2}. Three of those criteria were then applied to judge the
chosen data representations.


\subsection{Interpretation of the Problem Description}
The problem description from the course homepage defines a spreadsheet
as a 'table'. Hence, a spreadsheet can be seen seen as a potentially
infinite table. A requirement given in the description is that the
implementation shall be more economic than an plain rectangular
structure covering all non-empty table elements. From those
descriptions it becomes obvious that a more concise description of
problem is the \emph{efficient implementation of a sparse matrix}. 

\subsection{Typical Usecases of a Spreadsheet}
During a user session, text, numbers, formulas and links to
other elements are stored in the table elements. In many usecases the
number of filled elements will be very low compared to the virtual
rectanglular set of elements that surrounds the outermost non-empty
table elements, hence the table is said to have a low \emph{fill
 ratio}. This is the main reason why the potential data structure
should only store non-empty elements.

Another property of a spreadsheet program is that the data
structure is represented in the graphical user interface. Due to the
size, there will usually just one part of the data be visible, hence
blockwise value lookup for scrolling over the data table is a very
common operation. Spreadsheets are often used to prepare sorted
lists. Hence rearranging the order of whole rows or columns is another
operation of importance. When spreadsheets are used for calculation
purposes, extensive linking between memeber elements of the
spreadsheet is common.

In a normal spreadsheet, there are usually more rows than columns
visible. This is just based on the simple fact that numbers and text
extend horizontally on the screen. However, this will most likely
influence how the user arranges data. Most likely, there will be more
operations involving just a single columns compared to just a single
row. If the data representation is asymetrical in terms of structure
or operations, this should be kept in mind for the implementation. 

\subsection{The datatype Spreadsheet}
As a consequence of the above considerations the interface of the
hypothetical datatype \textit{spreadsheet} needs a basic set of
operations shown in listing \ref{ls:operations}. 

\begin{listing}
\begin{verbatim}
create(xy) -> s
HasValue(s,xy) -> bool
set(s,xy, v) -> s
inspect-value(s,xy) -> v
remove(s, xy) -> s
\end{verbatim}
\caption{\textit{shows the most basic operations that the data
  representation of a spreadsheet needs to implement \label{ls:operations}}}
\end{listing}

The most significant difference to a standard array as shown in
Janlert \cite[pp. 92-95]{janlert2000} is the non existance of $low$ or
$high$ operations. This is the consequence of the requirement that the
spresheet is of infinite size. 




\section{Chosen Criteria}
\subsection{Time Complexity}
The speed of specific operations is an important criteria. In some
cases, it could decide whether a ceratin construction is feasible at
or not. Whith `speed' I would define the processing time needed at a
realistic use case size of the instance in question. Hence, sometimes
a bad complexity can be accepted as the typical realworld instance
size happens to be in a very narrow bandwith. If possible, also the
time complexity of individual operations will be asessed.    

The chosen operations of interest are given below:

\begin{itemize}
\item Block Lookup - Get values for a block of cells. This operation
  will usally be applied when the user scrolls or jumps to another
  place in the spreadsheet. Block lookup differs from a normal lookup
  that both elements from both various rows and columns have to be
  looked up. 
\item Deletion - Deleting elements of the spreadsheet.
\item Value Search - Traversing the data structure to search for a
  user entered value in the spreadsheet elements. 
\end{itemize}

\subsection{Ease of Implementation}
During OU2 discussion, it was agreed that a lower complexity
of the implementation is generally desirable as it decreases the
susceptibility for bugs and code maintenance. How complex a certain
datatype is to implement is not an objective measure. The presented
evaluation is based on the authors' currentl experience level. 


\subsection{Memory efficency}
It is understood from the problem definition that the used
construction shall store just non-empty spreadsheet elements. Hence
the judgement of memory efficency focuses on the amount of
memory used for `administration' of the non-empty elements.

\section{Chosen Datatypes}
After a short literature study three datatypes were chosen to be
evaluated in more depth.

\begin{enumerate}
\item Array
\item Binary Tree
\item Directed Acyclic Graph
\end{enumerate}

Array was chosen as there was a description in the course litterature
about implementation of a sparse matrix \cite{janlert2000}. The binary
tree was chosen after deciding that time complexity was the maybe most
critical criteria in the data representation and that binary search
trees offer a very good time complexity. Finally, Directed Acyclic (DAG)
Graphs were chosen after having found indications on the web, that
DAGs are a common way how industry standard spreadsheets are
implemented \cite{spreadsheet1}\cite{spreadsheet2}\cite{spreadsheet3}.   


\subsection{Construction of Datatypes}
\subsubsection{Array}
The abstract datatype \emph{array} ressembles the description of 
how a spreadsheet is defined. However, when looking at the problem 
description, it became obvious that the physical datatype array was 
not suited as representation as an \emph{efficient representation of a
 sparse matrix}. Janlert \cite[pp 101-103]{janlert2000} suggest in
such a case to construct the array from a vector of tables. In C, the
array is a physical datatype. Typical for the datatype array, it can
not be resized during runtime. Hence this construction interpretes the
requirement of a infinite large spreadsheet by chosing a large enough
length for the row dimension. This seems to be an accepted choice:
\textit{Microsoft Excel}, one of the arguably most popular spreadsheet
applications on the market, has for example a row/column limitation of
1'048'576/16'384 \cite{excel_limit}.

There is no physical datatype \textit{table} in C. In this case construction
from a dynamic datatype such as \textit{linked list} seems to be reasonable. As
there is also no physical datatype \textit{list} in C, the construction could
be done through the complex datatype \textit{struct} linked with
\textit{pointers}. An example of the datatypes \textit{list} and
\textit{table} implemented as described above is available on the course
web page \cite{datatypes}.

In this construction, columns are accessed directly through the array
index and rows by looking up the value associated to the key that
represents the row number (the course litterature uses the term
\textit{argument} instead of \textit{key}\cite{janlert2000}).
 

\subsubsection{Binary trees}
\textit{Binary search trees} offer a good time complexity. Therefore
they were also considered for construction of a table trees. 
Here, the row index was represented in one \textit{binary tree}. The
label of each node contains the column index and a pointer to
another \textit{binary tree} for representing the row indices. 
Hence, for each node of the column tree, there is an additional row
\textit{binary tree}. The nodes in the row trees have a label that
contains both the row index and the actual value. 

In C, the construction of a binary tree is by using pointers to link
\textit{structs}. An implementation according to Janlert
\cite{janlert2000} was available through the course homepage \cite{datatypes}.



\subsubsection{Directed Acyclic Graph and Hash Table}
When thinking about the \emph{link} or \emph{reference} feature that most
spreadsheets make heavy use upon, a table constructed from a graph
should be an intersting possibility.  A directed acyclic graph or
\textit{DAG} is an n-linked structure. The nodes can be
constructed as cells which are created dynamically on demand. In C, a
struct would be the natural choice. Edges represent links in the
spreadsheet. They are also created dynamically, in C as pointers. 

To access individual cells, a hash table with a continuous numbering
system, either along the rows or columns of the table can be
used. Alternatively, the keys for the hash table can be the
concatenation of the spreadsheet table coordinates. In C a
datatype \textit{hash table} is not available by default and has to be
constructed. The underlying datatype is a table as described
earlier. For simplicity, \emph{open hashing} with \emph{linear
 probing} and a simple hash function such as \textit{modulo} was
chosen \cite[p. 277]{janlert2000}. 


\section{Evaluation of Data Representations}
All data representations are evaluated seperately and later compared
in the discussion section.
\subsection{Time Complexity}
\subsubsection{Array}
Looking up elements in a spreadsheet is always a composite of both row
and column lookup. Here, the column lookup is of $O(1)$ based on array
index access for the row while the row lookup is of $O(n)$, a
consequence of the chosen construction of the \textit{table}
(\textit{linked list}). Hence, \emph{Block Lookup} in this representation
is in the order of $O(n)$. \emph{Deletion} of spreadsheet elements is
also of $O(n)$. \emph{Searching} for values is rather slow as the whole
data structure has to be traversed: the time complexity is in the
order of $O(n)$.

As explained earlier, it was delibarately chosen to have the vector of tables
along the column indices such that one table contains all values for
one column.

\subsubsection{Binary Tree}
Average value lookup in binary trees is in the order of
$O(log(n))$. This implementation uses two binary search tree runs in
sequence, first for the column and then for the row index. Hence the
complexity for \emph{Block Lookup} is also $O(log(n))$.

\emph{Deletions} are of the same time complexity, however, significant 
structural reshuffeling is needed when nodes close to the root are deleted. 
\emph{Searching} for values is in this case just $O(n)$ as all
nodes have to be traversed. This is because the order relation in the
binary trees is based on their spreadsheet coordinates and not on the user
value entered in spreadsheet elements.




\subsubsection{Direced Acyclic Graph (DAG) with Hash Table}
Lookup speeds in a \textit{hashtable} are in the order of $O(1)$ which
applies also to \emph{Block Lookup} speed. The same is true for
\emph{Deletions}. \emph{Searching} is on an avarage $O(n)$ as all stored values
have to be looked up. This is a consquence of the fact that we are
hashing for spreadsheet coordinates and not spreadsheet element user
values. The fact that the whole structure is implemented as a DAG has
no inflence on the time complexity here. 

\subsection{Ease of Implementation}
\subsubsection{Array}
Implementing a spreadsheet using \textit{array} as data representation
is straight forward as a spreadsheet basically is an array. In the
present case the array needs to be constructed from a vector of
tables, but these are still rather simple datatypes and they are all
available on the course homepage.

Implementing the operations stated in listing \ref{ls:operations}
is also straight forward: column access is directly by indexing and
the table uses a \textit{lookup} operation. If the table is
constructed from a linked list, this will result in a list traversal. 



\subsubsection{Binary Tree}
Building the basic structure of the \textit{binary tree}
implementation is rather simple as the underlying data
types are available on the course homepage. However, the whole
representation feels less intuitive because a tree does not really
ressembles a spreadsheet. A binary tree has a very rich set of
operations. Mapping the spreadsheet interface to the binary tree is
certainly possible but a concise treatment of this issue would go
beyond the current report.


\subsubsection{Directed Acyclic Graph (DAG) with Hash Table}
The DAG purely as structure is simple to implement: The individual
nodes are basically a dynamic resource that is allocated when needed
and removed on deletion. However, implementing a hash table in C is
certainly not trivial and will require a fair amount of work. Also a
number of design choices have to be take such as whether \textit{open}
or \textit{closed} hashing shall be used. Here, the possibilites start
to fan out such that a concise treatement of the topic would be beyond
the scope of this report. Generally, it can be said that hash tables
offer superior time complexity. But for real world application, they
often have to be adapted for more balanced characteristics between
time and space complecity. Hence this will increase the complexity for
implementation.

\subsection{Memory Efficency}
\subsubsection{Array}
The described array representation for a spreadsheet is quite memory
efficient. One dimension, in the current case the column index vector,
is chosen to be static. while the tables for the row indices
and the corresponding user values are created dynamically on demand
during the user session.  

\subsubsection{Binary Tree}
The whole representation is dynamically created during the user
session and holds in both dimensions just elements for used row and
column indices. As such, this representation is very memory efficient.


\subsubsection{Directed Acyclic Graph (DAG) with Hash Table}
The amount of memory used depends on the chosen size for the hash
table. If it is chosen large enough to cover post possible use cases,
the overhead is rather big. A smaller, more memory efficient hash
table will require more advanced algorithms, for example for rehashing
in case the current hashtable fills above a certain fill ratio. 


\section{Discussion}
\subsection{Comparison of the different representations}
Results from evaluating the three datatypes according to the defined
criteria are summarized in table \ref{tab:eval}. There is obvious
clear winner. It seems like all three representations are feasible and
could be chosen for a certain application envelope. Probably the
situation would become clearar if the application envelope would be
specified in more details than it currently is.

I interpreted this exercise to be rather data structure centric and
not so much functional. I realized this after I chose the data type
DAG, mostly because I found it mentioned in litterture. It seems like
the only interesting property of the DAG in the spreadsheet respect is
for linking spreadsheet elements. While this functionality is in my
experience very important in a `real' spreadsheet application, it was
not really mentioned in the specifications for this exercise. As such,
it turned out that it was more the hash table that made large impact
for the third datatype.

The hashtable turned out to be some sort of magic bullet that performs
well in almost every respect. However, when searching the net
and litterature about hash tables, it was found that there are quite a
number of details that need to be decided and optimized for each
application case. The time complexity advantage is basically bought
with a worse space complexity. In the most simple case, the hash table
size is static and has to be decided pre-runtime. There are certainly
implementations described that allow `re-hashing' to adjust the hash
table size during run time, but then the complexity of implementation
increased considerably.

After comparing the different representations, an interesting
observation was that the array implementation with a vector of tables
could basically serve as hash table when using `open hashing'. Hence,
there could be a possibility to start the project with a very simple
implementation, and later, when time complexity turns out to be an
issue, step up to a more complex implementation on basically the same
code basis. 

The binary tree implementation seems to perform somewhere in between
the array and the DAG/hash table. However, it feels a bit like a black
box as the actual data structure does not ressemble much the
underlying data. For all use cases that where envisoned, the structure
seems to work, but the implementation does not feel to be very
intuitive. 

\subsection{Conclusions}

As mentioned earlier, more details about the required functionality of
the spreadsheet application would be needed to make a more consicise
evaluation. My first impression was that I would probably start with a
very simplistic implementation using the \textit{array} constructed
through a \textit{vector} of \textit{tables}. However, after I've seen
the code snippet in reference \cite{spreadsheet2}, I am in favour of
the hash table combined with a DAG. I was impressed by the simplicity
of this implementation. In fact, it seems that the initial
work would concentrate mostly on implementing the hash table with
links to structs that later will serve as nodes in a DAG. A
simplistic hash table can be coded rather quick. When developing
software, I prefer to have first a functioning framework of the whole
application with simplistic versions of each part (could be hardcoded
or dummy) already in place instead of perfecting individual parts
prior to putting pieces together. 

\begin{table}[]
\centering
\caption{Evaluation of the data representations according to the chosen criteria}
\label{tab:eval}
\begin{tabular}{llccc}
                       &              & Array      & Binary Tree  &
                       DAG /Hash Table \\ \hline
Time Complexity        &              &            &              &
\\
                       & Block Lookup & slow       & fast         &
                       very fast       \\
                       & Deletion     & fast       & fast         &
                       very fast       \\
                       & Value Search & slow       & slow         &
                       slow            \\
Ease of Implementation &              & simple     & intermediate &
rather advanced \\
Space Complexity       &              & quite good & very good    &
rather low     
\end{tabular}
\end{table}

\addcontentsline{toc}{section}{\refname}
\bibliography{references}

\end{document}
